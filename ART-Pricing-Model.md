# **The ART Pricing Model**

*Adaptive Rate Token: A Framework for Virtualized, Self-Liquidating Pricing Model*

# **Executive Summary**

The Adaptive Rate Token (ART) model provides a unified framework for pricing AI model consumption. It virtualizes provider costs into a single billable unit, enforces fiscal discipline through self-liquidating economics, and maintains fee efficiency with payment processors. The model works whether we absorb provider costs or pass them through to users who bring their own model credentials.

This document serves two purposes. First, it explains the strategic logic behind each design decision. Second, it provides the complete technical specification for implementation. Read it once for understanding, then reference it during build.

# **Why Self-Liquidating Economics**

Every customer costs money to acquire. Marketing spend, sales effort, onboarding support, promotional credits: these costs accumulate before a customer generates their first dollar of revenue. The question every business must answer is simple. When does a customer pay back their acquisition cost?

Most SaaS companies defer this question. They acquire customers aggressively, hope retention holds, and trust that lifetime value will eventually exceed acquisition cost. This approach works in bull markets with cheap capital. It fails when funding tightens, growth slows, or unit economics come under scrutiny.

Self-liquidating economics inverts this model. Instead of hoping customers eventually become profitable, we design pricing to ensure they become profitable quickly. Within a defined window (we use 30 days), each customer's gross profit must equal or exceed their acquisition cost. No exceptions. No deferrals. No hope.

## **The Mechanics**

Self-liquidation requires three inputs: the cost to acquire a customer (CAC), the gross margin per unit sold, and the expected consumption within the payback window. Multiply margin by consumption. If the result exceeds CAC, the customer self-liquidates. If it falls short, something must change.

That change can take several forms. We can require a larger first purchase. We can add fees that boost initial ARPU. We can gate expensive features until usage patterns prove out. The mechanism matters less than the outcome: every customer must reach profitability within the window.

## **Why This Matters for AI Products**

AI products face a unique challenge. Variable costs are real and significant. Every API call to OpenAI or Anthropic costs money. Unlike traditional SaaS where marginal cost approaches zero, AI products have meaningful cost of goods sold on every request. A customer who uses the product heavily but pays little can actually lose money on a per-interaction basis.

This makes self-liquidating economics not just prudent but essential. We cannot afford to acquire customers who consume more value than they pay for. The ART model builds this discipline into the pricing structure itself. Minimum purchases, margin floors, and consumption-based billing all work together to ensure that usage generates profit, not loss.

## **The Business Case**

Self-liquidating economics enables sustainable growth. When every customer pays back their acquisition cost within 30 days, growth becomes self-funding. Revenue from month one covers the cost of acquiring customers in month two. The business generates cash instead of consuming it.

This changes how we think about scaling. Traditional venture-backed growth trades cash for customers, betting that future monetization will justify current losses. Self-liquidating growth trades customers for cash from day one. We can grow as fast as we can acquire profitable customers, without external capital constraints.

The ART pricing model exists to make this possible. Every design decision, from token virtualization to minimum order thresholds to BYOM support, serves the same goal: ensuring that customer acquisition creates value rather than destroys it.

# **Core Concepts**

Before diving into mechanics, we need shared vocabulary. These definitions form the foundation of every calculation that follows.

## **Definitions**

1. **Model Tokens:** The raw units consumed from AI providers. Input tokens (what users send) and output tokens (what models return) are counted separately, as providers price them differently.  
2. **Adaptive Rate Token (ART):** Our internal billable unit. One ART equals 1,000 model tokens. This abstraction decouples our pricing from provider rate changes and enables consistent user experience across models.  
3. **Cost of Delivery (CoD):** All variable costs incurred per request. This includes model provider fees (when applicable), vector database operations, bandwidth, and observability infrastructure. CoD varies by model tier and request complexity.  
4. **Lifetime Gross Profit (LTGP):** The cumulative gross profit generated by a customer over their observed or projected lifetime. Gross profit equals revenue minus CoD.  
5. **Customer Acquisition Cost (CAC):** The fully loaded cost to acquire a customer. This includes marketing spend, sales effort, onboarding resources, and any promotional credits extended.  
6. **Self-Liquidating:** A pricing structure where expected LTGP equals or exceeds CAC within a defined payback window. Our default target is 30 days. When a customer self-liquidates, they have paid back their acquisition cost and begun generating net profit.

# **The ART Abstraction**

Why virtualize tokens at all? Three reasons drive this decision.

Provider pricing changes constantly. OpenAI, Anthropic, and others adjust rates without notice. A virtualized unit insulates users from this volatility. They see stable ART prices while we absorb and manage provider fluctuations behind the scenes.

Different models cost different amounts. A request to GPT-4 costs more than one to GPT-3.5. Without abstraction, users would need to track dozens of rate cards. ART simplifies this. Users understand one price. We handle the complexity of model-specific economics internally.

The 1,000-to-1 ratio creates human-readable numbers. Nobody wants to see bills denominated in millions of tokens. ART converts those millions into thousands, making consumption intuitive to grasp and compare.

# **Stripe Fee Efficiency**

Payment processing fees contain two components: a percentage of the transaction and a fixed fee per transaction. For Stripe in the US, this typically means 2.9% plus $0.30. The percentage scales with order size. The fixed fee does not. On a $1 purchase, that $0.30 represents 30% of revenue. On a $100 purchase, it represents 0.3%.

This asymmetry demands a minimum purchase threshold. We target keeping processing fees at or below 5% of order value. The math is straightforward.

## **Minimum Order Calculation**

Let p equal the percentage fee (0.029 for 2.9%). Let f equal the fixed fee ($0.30). Let r equal our target maximum fee share (0.05 for 5%). We solve for the minimum order M where total fees remain at or below our target:

p × M \+ f ≤ r × M  
f ≤ r × M \- p × M  
f ≤ M × (r \- p)  
M ≥ f / (r \- p)

With standard Stripe fees: M ≥ 0.30 / (0.05 \- 0.029) \= 0.30 / 0.021 ≈ $14.29. We round up to $15 for simplicity and buffer. This becomes our minimum top-up amount.

## **Bundle Tiers**

Beyond the minimum, we offer preset bundles at $25, $49, $99, and $199. Larger bundles improve fee economics further and reduce top-up frequency. Users who purchase higher tiers signal commitment and typically exhibit better retention. The bundle structure also enables promotional mechanics, such as bonus ART for larger purchases, without disrupting base economics.

# **Price Ladder and Margins**

Every ART sold must cover its costs and contribute to margin. The cost per ART combines provider costs (when we pay them) and infrastructure overhead (always present).

## **Cost Composition**

cost\_per\_AT \= (provider\_cost\_per\_1M / 1,000,000) × 1,000 \+ infra\_overhead\_per\_AT

The first term converts provider pricing (typically quoted per million tokens) down to our 1,000-token ART unit. The second term adds our infrastructure costs: vector database queries, bandwidth, logging, and observability. This overhead applies regardless of whether the user brings their own model.

## **Margin Floor**

We target a minimum 70% gross margin at bundle scale. This margin must absorb promotions, support costs, and provide operating leverage as we scale. The floor price calculation ensures we never sell below sustainable economics:

floor\_price \= cost\_per\_AT / (1 \- min\_margin)

Example:  
Provider blended cost: $10 per 1M tokens → $0.01 per ART  
Infrastructure overhead: $0.002 per ART  
Total cost\_per\_AT: $0.012  
With 70% minimum margin: floor \= 0.012 / (1 \- 0.7) \= $0.04  
Actual sell\_price\_per\_AT: $0.05 (provides room for promotions)

# **LTGP/CAC Self-Liquidation**

Acquiring customers costs money. If those customers never generate enough gross profit to cover their acquisition cost, the business bleeds cash with every signup. Self-liquidation ensures this does not happen.

## **The Payback Window**

We define a 30-day payback window as our default target. Within 30 days of acquisition, a customer's gross profit should equal or exceed their CAC. This window balances growth velocity against capital efficiency. Shorter windows constrain growth. Longer windows strain cash flow.

## **The Self-Liquidation Test**

expected\_consumption\_AT\_30d \= (from cohort data or user's early behavior)  
gm\_per\_AT \= sell\_price\_per\_AT \- cost\_per\_AT  
expected\_LTGP\_30d \= expected\_consumption\_AT\_30d × gm\_per\_AT

Self-liquidation passes when: expected\_LTGP\_30d ≥ CAC\_30d

When a new user signs up, we estimate their 30-day consumption based on cohort baselines or their early usage patterns. If projected gross profit falls short of CAC, the system intervenes.

## **Enforcement Mechanisms**

When self-liquidation fails, we have several levers:

* **Raise minimum first purchase:** Require $49 or $99 instead of $15 for the initial bundle  
* **Add onboarding fees:** Introduce setup fees or seat fees that contribute to first-purchase ARPU  
* **Gate model access:** Default to cheaper models until usage patterns demonstrate higher ARPU potential

# **Bring Your Own Model (BYOM)**

Some users prefer to use their own model provider credentials. They may have negotiated enterprise rates, require specific compliance configurations, or simply want direct control over their AI spend. The ART model accommodates this through OpenRouter integration.

## **How BYOM Works**

Users connect their OpenRouter API key to our platform. OpenRouter acts as a unified gateway to multiple AI providers, so a single key grants access to OpenAI, Anthropic, Google, and others. When a BYOM user makes a request, we route it through their OpenRouter credentials. The provider charges them directly.

This changes the economics significantly. We no longer pay provider costs for these users. Their cost\_per\_AT drops to infrastructure overhead alone:

// Standard user:  
cost\_per\_AT \= provider\_cost \+ infra\_overhead

// BYOM user:  
cost\_per\_AT \= infra\_overhead only

## **BYOM Pricing Strategy**

With provider costs removed from our side, we have options. We can pass savings to BYOM users through reduced ART prices, improving their unit economics. Alternatively, we can maintain standard ART pricing and capture higher margins. The right choice depends on competitive positioning and customer segment.

Our recommended approach: charge BYOM users for infrastructure only, at a materially lower ART rate. This creates clear value for users who bring their own credentials while still generating margin on every request. The transparency builds trust. Users see exactly what they pay us for (infrastructure, interface, features) versus what they pay providers for (model compute).

## **BYOM Implementation Notes**

* Store OpenRouter API keys encrypted, with user-controlled rotation capabilities  
* Validate key permissions on connection to ensure required model access  
* Display clear attribution in receipts: infrastructure costs (billed to us) versus provider costs (billed directly to user)  
* Handle OpenRouter rate limits and errors gracefully with user-facing status  
* Meter ART consumption identically to standard users for consistent analytics

# **User Experience Flow**

The system should feel simple to users while handling complex economics behind the scenes. Here is the intended experience:

## **Top-Up Flow**

User selects a bundle (minimum $15, or $25/$49/$99/$199). We create a Stripe checkout session. On successful payment, we credit both their USD wallet balance and their ART balance at the current sell price. The conversion happens instantly and transparently.

## **Request Metering**

Every API request counts tokens. Input and output tokens convert to ART using ceiling division (a request using 1,500 tokens consumes 2 ART, not 1.5). We deduct ART from the user's balance immediately. If balance runs low mid-session, we prompt for top-up without blocking the current request. Interrupting work flow destroys user experience.

## **Model Selection**

By default, we route to the cheapest capable model for each task. Users can override this, selecting more powerful (and expensive) models. The interface shows the ART cost delta clearly before they confirm. Power users get control. Casual users get efficiency.

## **Receipts and Transparency**

Every request generates an itemized receipt: model tokens consumed, ART charged, cost of delivery breakdown, margin earned. Users can export this data. Transparency builds trust and helps users optimize their own usage patterns.

## **Dashboard Indicators**

The user dashboard includes an LTGP/CAC tile showing their payback status: green (self-liquidating), amber (on track), or red (needs attention). We also display estimated days to payback. This transparency extends our internal metrics to users, aligning incentives around sustainable usage.

# **Engineering Specification**

This section provides implementation details. The data model, core functions, and API endpoints below should enable direct implementation without ambiguity.

## **Data Model**

### **pricing\_models**

Stores provider-specific cost data for each model we support.

| Column | Description |
| :---- | :---- |
| id | Primary key |
| name | Model identifier (e.g., gpt-4-turbo, claude-3-opus) |
| provider\_cost\_in\_per\_1M | Provider cost for input tokens per 1M |
| provider\_cost\_out\_per\_1M | Provider cost for output tokens per 1M |
| enabled | Boolean flag for availability |
| effective\_at | Timestamp when this pricing becomes active |

### **pricing\_system**

System-wide pricing configuration. Single row, updated as needed.

| Column | Description |
| :---- | :---- |
| art\_per\_unit | Model tokens per ART (default: 1000\) |
| sell\_price\_per\_art | USD price per ART to customers |
| infra\_overhead\_per\_art | Infrastructure cost per ART (always applies) |
| min\_margin | Target minimum gross margin (e.g., 0.70) |
| stripe\_pct | Stripe percentage fee (e.g., 0.029) |
| stripe\_fixed | Stripe fixed fee (e.g., 0.30) |
| max\_fee\_share | Maximum acceptable fee percentage (e.g., 0.05) |
| min\_order\_usd | Derived minimum order (e.g., 15.00) |
| bundles | JSON array of bundle amounts \[15, 25, 49, 99, 199\] |

### **wallets**

User balance and lifecycle tracking.

| Column | Description |
| :---- | :---- |
| user\_id | Foreign key to users table |
| usd\_balance | Current USD credit balance |
| art\_balance | Current ART credit balance |
| lifecycle\_stage | Enum: trial, active, high\_usage |
| cac\_bucket\_id | Reference to acquisition cohort for CAC lookup |
| is\_byom | Boolean: user brings own model credentials |
| openrouter\_key\_enc | Encrypted OpenRouter API key (null if not BYOM) |

### **usage\_events**

Immutable log of every billable request.

| Column | Description |
| :---- | :---- |
| id | Primary key |
| user\_id | Foreign key to users |
| model\_id | Foreign key to pricing\_models |
| input\_tokens | Raw input token count from provider |
| output\_tokens | Raw output token count from provider |
| art\_used | Total ART deducted for this request |
| cod\_usd | Cost of delivery in USD |
| is\_byom | Boolean: was this a BYOM request |
| timestamp | UTC timestamp of request |
| request\_id | Unique identifier for idempotency |

### **cohort\_metrics (daily rollup)**

Daily snapshot of user-level economics for self-liquidation tracking.

| Column | Description |
| :---- | :---- |
| user\_id | Foreign key to users |
| date | Date of this snapshot |
| expected\_art\_30d | Projected 30-day ART consumption |
| expected\_ltgp\_30d | Projected 30-day lifetime gross profit |
| cac\_30d | CAC applicable to this user |
| ltgp\_over\_cac | Ratio: expected\_ltgp\_30d / cac\_30d |
| status\_color | Enum: green, amber, red |

## **Core Functions**

These functions implement the business logic. Language-agnostic pseudocode is provided; adapt to your stack.

### **derive\_min\_order**

Calculates the minimum order threshold to maintain fee efficiency.

function derive\_min\_order(stripe\_pct, stripe\_fixed, max\_fee\_share):  
    \# Ensure percentage fee is less than target share  
    assert stripe\_pct \< max\_fee\_share  
    raw\_min \= stripe\_fixed / (max\_fee\_share \- stripe\_pct)  
    return ceil\_to\_nearest\_dollar(raw\_min)

### **art\_cost\_per\_request**

Computes the cost of delivery for a single request. Handles both standard and BYOM scenarios.

function art\_cost\_per\_request(model, in\_tokens, out\_tokens, is\_byom):  
    art\_in \= ceil(in\_tokens / 1000\)  
    art\_out \= ceil(out\_tokens / 1000\)  
      
    \# Infrastructure cost always applies  
    infra\_cost \= (art\_in \+ art\_out) \* INFRA\_OVERHEAD\_PER\_ART  
      
    if is\_byom:  
        \# BYOM users pay provider directly; we only charge infra  
        return infra\_cost  
      
    \# Standard users: add provider costs  
    cost\_in\_per\_art \= model.provider\_cost\_in\_per\_1M / 1\_000\_000 \* 1000  
    cost\_out\_per\_art \= model.provider\_cost\_out\_per\_1M / 1\_000\_000 \* 1000  
    provider\_cost \= art\_in \* cost\_in\_per\_art \+ art\_out \* cost\_out\_per\_art  
      
    return provider\_cost \+ infra\_cost

### **art\_billable\_units**

Converts raw token counts to billable ART units.

function art\_billable\_units(in\_tokens, out\_tokens):  
    return ceil(in\_tokens / 1000\) \+ ceil(out\_tokens / 1000\)

### **ensure\_margin\_floor**

Validates that sell price maintains minimum margin.

function ensure\_margin\_floor(cost\_per\_art, min\_margin):  
    floor\_price \= cost\_per\_art / (1 \- min\_margin)  
    return ceil\_to\_cents(floor\_price)

### **self\_liquidates**

Tests whether a user's projected consumption will cover their CAC.

function self\_liquidates(expected\_art\_30d, sell\_price, cost\_per\_art, cac\_30d):  
    gm\_per\_art \= sell\_price \- cost\_per\_art  
    expected\_ltgp\_30d \= expected\_art\_30d \* gm\_per\_art  
    return expected\_ltgp\_30d \>= cac\_30d

### **recommended\_first\_bundle**

Determines the appropriate first purchase tier for a new user based on self-liquidation requirements.

function recommended\_first\_bundle(user):  
    expected\_art\_30d \= estimate\_from\_cohort(user)  
    cost\_per\_art \= get\_cost\_per\_art(user.is\_byom)  
      
    if self\_liquidates(expected\_art\_30d, SELL\_PRICE, cost\_per\_art, user.cac\_30d):  
        return max(MIN\_ORDER\_USD, 15\)  
      
    \# Scale up to hit payback  
    gm\_per\_art \= SELL\_PRICE \- cost\_per\_art  
    needed\_revenue \= user.cac\_30d  
    needed\_art \= ceil(needed\_revenue / gm\_per\_art)  
    bundle\_value \= find\_next\_bundle(\[25, 49, 99, 199\], needed\_art \* SELL\_PRICE)  
      
    return bundle\_value

## **API Endpoints**

1. **POST /pricing/quote**  
   Returns cost estimate before executing a request.

Request:  { model\_id, input\_tokens, output\_tokens }  
Response: { art\_used, est\_cost\_usd, est\_margin\_usd, model\_alternatives: \[...\] }

2. **GET /pricing/bundles**  
   Returns available purchase tiers and their economics.

Response: { min\_order\_usd, bundles: \[15, 25, 49, 99, 199\],  
           stripe\_fee\_share\_per\_bundle: \[...\] }

3. **POST /wallet/topup**  
   Initiates a purchase. Creates Stripe checkout session, credits wallet on success.

Request:  { bundle\_usd } (validated \>= min\_order\_usd)  
Effect:   Creates Stripe session; on success: credit usd\_balance,  
          art\_balance \= floor(usd / sell\_price\_per\_art)

4. **POST /usage/commit**  
   Records a completed request. Deducts ART, logs CoD, updates metrics.

Request:  { request\_id, model\_id, input\_tokens, output\_tokens }  
Effect:   Deducts art\_used, records cod\_usd, updates cohort\_metrics

5. **GET /unit-economics/summary**  
   Returns the LTGP/CAC dashboard data for the authenticated user.

Response: { expected\_art\_30d, gm\_per\_art, expected\_ltgp\_30d,  
           cac\_30d, ltgp\_over\_cac, status, payback\_days\_estimate }

6. **POST /settings/byom**  
   Configures BYOM mode for a user.

Request:  { openrouter\_api\_key }  
Effect:   Validates key, encrypts and stores, sets is\_byom \= true

## **Admin Controls**

The admin interface should expose the following capabilities:

* Toggle model availability (enable/disable specific models)  
* Update provider cost tables as rates change  
* Adjust infrastructure overhead per ART  
* Modify max\_fee\_share target and recalculate min\_order  
* Edit bundle tiers  
* A/B test sell\_price\_per\_art across cohorts  
* View per-cohort payback curves and self-liquidation rates  
* Configure BYOM pricing (infra-only rate)

# **Rollout Playbook**

A phased approach reduces risk and allows iteration based on real data.

1. **Launch with conservative defaults.** Set minimum order at $15 with bundles at $25, $49, $99, and $199. Price ART at $0.05 (adjust based on your actual costs). Monitor fee share and margins daily for the first two weeks.  
2. **Gate expensive models.** Place high-cost models (GPT-4, Claude Opus) behind an "ART Surge Preview" flag. Show users the cost delta before they opt in. This protects margins while giving power users access.  
3. **Enable BYOM as opt-in.** Launch BYOM for users who request it. Validate OpenRouter integration thoroughly before broader rollout. Document the setup process clearly.  
4. **Activate self-liquidation guardrails.** Turn on the LTGP/CAC check for new cohorts only. Existing users keep their current minimums. Nudge first bundle size upward when projections fall short.  
5. **Expose the economics dashboard.** Once self-liquidation logic is validated, show users their LTGP/CAC tile. Transparency drives trust and helps users understand the value exchange.  
6. **Iterate on pricing.** After 30 days of data, review cohort payback curves. Adjust sell\_price\_per\_art, bundle tiers, or BYOM pricing as needed. Small changes, measured carefully.

# **Summary**

The ART pricing model accomplishes three things. It virtualizes AI provider costs into a single, manageable unit. It enforces fiscal discipline through self-liquidating economics. And it maintains payment processor efficiency through minimum order thresholds.

For BYOM users, the model adapts cleanly. Provider costs disappear from our side of the equation. Infrastructure costs remain. The same ART abstraction, metering, and self-liquidation logic applies. Users who bring their own credentials get transparent pricing for the value we actually provide: the platform, the interface, and the infrastructure.

Build the tables. Implement the functions. Wire up the endpoints. The specification above contains everything needed to ship a production-ready system.
